#!/usr/bin/env node

const chalk = require('chalk');
const crypto = require('crypto');
const path = require('path');
const fs = require('fs-extra');
const postcss = require('postcss');
const postcssURL = require('postcss-url');
const posthtml = require('posthtml');
const posthtmlBeautify = require('posthtml-beautify');
const posthtmlURL = require('posthtml-urls');
const posthtmlCSS = require('posthtml-postcss');
const Terser = require('terser');
const Url = require('url-parse');

const assetsDirPrefix = '/assets';
// The dir that Eleventy builds to.
const builtAssetDir = path.resolve(__dirname, '../build/');
// Where we're writing to.
const destAssetDir = path.resolve(__dirname, '../dist/');

// Binary assets are handled first
const binaryAssetsRX = /\.(?:ico|jpe?g|png|tiff|webp|eot|gif|otf|ttf|woff2?)$/;

// Text-based assets consume other assets so they need to be revved after the images.
const textAssetsRX = /\.(?:js|css|svg)$/;

// Assets that match these endings should not be hashed.
const unHashableAssetsRX = /(?:robots\.txt|\.html|pages\.json)$/;

function getPathRelativeToCWD(assetPath) {
  return path.relative(process.cwd(), assetPath);
}

// The asset map is the main data structure that holds the paths.
async function getFileHash(path) {
  const shasum = crypto.createHash('sha256');
  const content = await fs.readFile(path, 'utf8');
  shasum.update(content);
  return shasum.digest('hex');
}

function getContentHash(content) {
  const shasum = crypto.createHash('sha256');
  shasum.update(content);
  return shasum.digest('hex');
}

function getHashedPath(keyPath, hash) {
  const ext = path.extname(keyPath);
  const shortHash = hash.substring(0, 8);
  return path.join(
    path.dirname(keyPath),
    `${path.basename(keyPath, ext)}.${shortHash}${ext}`
  );
}

async function recursiveListDir(directoryName, mapObject) {
  let files = await fs.readdir(directoryName, { withFileTypes: true });
  for (let file of files) {
    let fullPath = path.join(directoryName, file.name);
    if (file.isDirectory()) {
      await recursiveListDir(fullPath, mapObject);
    } else {
      const filePath = path.relative(builtAssetDir, fullPath);
      if (!mapObject[filePath]) {
        mapObject[filePath] = { hashedPath: null };
      }
    }
  }
  return mapObject;
}

function updateKeys(obj, key, fileHash, written) {
  const shortHash = fileHash.substring(0, 8);
  obj[key].hash = fileHash;
  obj[key].shortHash = shortHash;
  obj[key].hashedPath = getHashedPath(key, fileHash);
  // Store a bool as to whether this file has been already written out to the target dir.
  obj[key].written = !!written;
  return obj[key];
}

function spliceString(str, begin, end, replacement) {
  return str.substr(0, begin) + replacement + str.substr(end);
}

async function updateHashMap(mapObject, rx, asyncFunc) {
  await Promise.all(
    Object.keys(mapObject).map(async (item, idx) => {
      if (item.match(rx)) {
        const origPath = path.join(builtAssetDir, item);
        if (asyncFunc) {
          await asyncFunc(origPath, item, mapObject);
        } else {
          const fileHash = await getFileHash(origPath);
          updateKeys(mapObject, item, fileHash);
        }
      }
    })
  );
  return mapObject;
}

function trimLeadingSlash(str) {
  return str.replace(/^\/{1}/, '');
}

function hasHashedReplacementURL(inputPath, assetMap) {
  const url = new Url(trimLeadingSlash(inputPath));
  if (
    assetMap.hasOwnProperty(url.pathname) &&
    assetMap[url.pathname].hashedPath &&
    !url.pathname.match(unHashableAssetsRX)
  ) {
    return true;
  }
  return false;
}

function getReplacementURL(inputPath, assetMap) {
  const origPath = trimLeadingSlash(inputPath);
  const url = new Url(origPath);
  if (hasHashedReplacementURL(url.pathname, assetMap)) {
    return `/${assetMap[url.pathname].hashedPath}${url.query}${url.hash}`;
  }
  return `/${inputPath}`;
}

async function rewriteBinaryFiles(origPath, key, assetMap) {
  const fileHash = await getFileHash(origPath);
  const hashedPath = getHashedPath(key, fileHash);
  const outputFile = path.join(destAssetDir, hashedPath);

  try {
    await fs.ensureFile(outputFile);
    await fs.copy(origPath, outputFile, { replace: false });
    console.log(`Writing Binary file to ${getPathRelativeToCWD(outputFile)}`);
    updateKeys(assetMap, key, fileHash, true);
  } catch (error) {
    console.error(chalk.red(`Error writing binary file: ${error}`));
  }
}

async function rewriteJS(origPath, key, assetMap) {
  let code = await fs.readFile(origPath, 'utf8');
  const ast = Terser.parse(code);
  const pathNodes = [];
  ast.walk(
    new Terser.TreeWalker(function (node) {
      if (node instanceof Terser.AST_String) {
        if (hasHashedReplacementURL(node.getValue(), assetMap)) {
          pathNodes.push(node);
        }
      }
    })
  );
  // now go through the nodes backwards and replace code
  const replacementsCount = pathNodes.length;
  if (replacementsCount) {
    console.log(
      `Re-writing ${replacementsCount} ${
        replacementsCount == 1 ? 'path' : 'paths'
      } in ${getPathRelativeToCWD(origPath)}`
    );
  }
  for (var i = pathNodes.length; --i >= 0; ) {
    const node = pathNodes[i];
    const start_pos = node.start.pos;
    const end_pos = node.end.endpos;
    const replacement = new Terser.AST_String({
      value: getReplacementURL(node.getValue(), assetMap),
    }).print_to_string({ beautify: true });
    code = spliceString(code, start_pos, end_pos, replacement);
  }

  const minified = Terser.minify(code);

  if (minified.error) {
    throw new Error(minified.error);
  }

  const hash = getContentHash(minified.code);
  const hashedPath = getHashedPath(key, hash);
  const outputFile = path.join(destAssetDir, hashedPath);

  try {
    await fs.ensureFile(outputFile);
    await fs.writeFile(outputFile, minified.code);
    console.log(`Writing minified JS to ${getPathRelativeToCWD(outputFile)}`);
    updateKeys(assetMap, key, hash, true);
  } catch (error) {
    console.error(chalk.red(`Error writing generated JS: ${error}`));
  }
}

async function rewriteHTML(origPath, key, assetMap) {
  let text = await fs.readFile(origPath, 'utf8');
  let replacementsCount = 0;

  const postcssOptions = { from: origPath };
  const postcssfilterType = /^text\/css$/;

  const output = await posthtml()
    .use(
      posthtmlCSS(
        [
          postcssURL({
            url: (asset) => {
              if (hasHashedReplacementURL(asset.url, assetMap)) {
                replacementsCount++;
                return getReplacementURL(asset.url, assetMap);
              } else {
                return asset.url;
              }
            },
          }),
        ],
        postcssOptions,
        postcssfilterType
      )
    )
    .use(
      posthtmlURL({
        eachURL: (url, attr, element) => {
          if (hasHashedReplacementURL(url, assetMap)) {
            replacementsCount++;
            return getReplacementURL(url, assetMap);
          } else {
            return url;
          }
        },
      })
    )
    //    .use(
    //      posthtmlBeautify({
    //        rules: {
    //          indent: 2,
    //          blankLines: false,
    //        },
    //      })
    //    )
    .process(text);

  const hash = getContentHash(output.html);

  if (replacementsCount) {
    console.log(
      `Re-writing ${replacementsCount} ${
        replacementsCount == 1 ? 'path' : 'paths'
      } in ${getPathRelativeToCWD(origPath)}`
    );
  }

  let outputFile;
  const ext = path.extname(origPath);
  if (ext !== '.html') {
    outputFile = path.join(destAssetDir, getHashedPath(key, hash));
  } else {
    outputFile = path.join(
      destAssetDir,
      path.relative(builtAssetDir, origPath)
    );
  }

  try {
    await fs.ensureFile(outputFile);
    await fs.writeFile(outputFile, output.html);
    const fileType = ext.replace(/^\./, '');

    console.log(`Writing ${fileType} to ${getPathRelativeToCWD(outputFile)}`);
    updateKeys(assetMap, key, hash, true);
  } catch (error) {
    console.error(chalk.red(`Error writing generated ${fileType}: ${error}`));
  }
}

async function rewriteCSS(origPath, key, assetMap) {
  let css = await fs.readFile(origPath, 'utf8');
  let replacementsCount = 0;
  const output = postcss()
    .use(
      postcssURL({
        url: (asset) => {
          if (hasHashedReplacementURL(asset.url, assetMap)) {
            replacementsCount++;
            return getReplacementURL(asset.url, assetMap);
          } else {
            return asset.url;
          }
        },
      })
    )
    .process(css, { from: origPath });

  const hash = getContentHash(output.css);

  if (replacementsCount) {
    console.log(
      `Re-writing ${replacementsCount} ${
        replacementsCount == 1 ? 'path' : 'paths'
      } in ${getPathRelativeToCWD(origPath)}`
    );
  }

  const hashedPath = getHashedPath(key, hash);
  const outputFile = path.join(destAssetDir, hashedPath);

  try {
    await fs.ensureFile(outputFile);
    await fs.writeFile(outputFile, output.css);
    console.log(`Writing CSS to ${getPathRelativeToCWD(outputFile)}`);
    updateKeys(assetMap, key, hash, true);
  } catch (error) {
    console.error(`Error writing generated CSS: ${error}`);
  }
}

async function copyFiles(assetMap) {
  await Promise.all(
    Object.keys(assetMap).map(async (pathKey, idx) => {
      const asset = assetMap[pathKey];
      if (asset && !asset.written) {
        const outputPath = asset.hashedPath ? asset.hashedPath : pathKey;
        const outputFile = path.join(destAssetDir, outputPath);
        const origFile = path.join(builtAssetDir, pathKey);

        try {
          console.log(
            `Copying file from ${getPathRelativeToCWD(
              origFile
            )} to ${getPathRelativeToCWD(outputFile)}`
          );
          await fs.copy(origFile, outputFile, { replace: false });
          asset.written = true;
        } catch (error) {
          console.error(`Error copying file: ${error}`);
        }
      }
    })
  );
}

async function cacheBustAssets() {
  // Get all file paths in the map from the build dir first.
  const assetMap = await recursiveListDir(builtAssetDir, {});

  // Update the assetMap with hashes for binary files.
  await updateHashMap(assetMap, binaryAssetsRX, rewriteBinaryFiles);

  // Process SVG
  await updateHashMap(assetMap, /\.svg$/, rewriteHTML);

  // Process JS files
  await updateHashMap(assetMap, /\.js$/, rewriteJS);

  // Process CSS
  await updateHashMap(assetMap, /\.css$/, rewriteCSS);

  // Process HTML
  await updateHashMap(assetMap, /\.html$/, rewriteHTML);

  // Finally copy everything to a new directory, if the original path has a hashed entry write it to that path.
  await copyFiles(assetMap);
}

cacheBustAssets()
  .then(() => {
    console.log(chalk.green('TA-DA! 🥁'));
  })
  .catch((error) => {
    console.log(chalk.red(`Something went wrong: ${error.message}`));
    console.error(error.stack);
    process.exit(1);
  });
